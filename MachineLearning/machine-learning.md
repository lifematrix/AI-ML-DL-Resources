

## Learning Theory

### Manifold Hypothesis

* [What is the Manifold Hypothesis?](https://deepai.org/machine-learning-glossary-and-terms/manifold-hypothesis) on [deepAI.org](deepai.org)

* **Testing The Manifold Hypothesis** by MIT [[Paper]](http://www.mit.edu/~mitter/publications/121_Testing_Manifold.pdf)

* Colab's blog: [Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)

### Boosting

#### Papers

* **XGBoost: A Scalable Tree Boosting System** (Chen Tianqi et al.; 2005) [[Paper]](https://arxiv.org/pdf/1603.02754.pdf)
  
* **Applied Multivariate Statistics Boosting Method by Beate Sick** (Beate Sick) [[Slides]](https://ethz.ch/content/dam/ethz/special-interest/math/statistics/sfs/Education/Advanced%20Studies%20in%20Applied%20Statistics/course-material-1719/Multivariate/slides12_boosting_presented.pdf)

* **Greedy Function Approximation: A Gradient Boosting Machine** (Jerome H. Friedman; 1999) [[Paper]](https://jerryfriedman.su.domains/ftp/trebst.pdf)

* **Boosting Algorithms as Gradient Descent** (Mason et al; NIPS 1999) [[Paper]](https://proceedings.neurips.cc/paper/1999/file/96a93ba89a5b5c6c226e49b88973f46e-Paper.pdf)

* **AdaBoost and the Super Bowl of Classifiers A Tutorial Introduction to Adaptive Boosting** (Rau ́l Rojas; 2009) [[Paper]](http://www.inf.fu-berlin.de/inst/ag-ki/adaboost4.pdf)

* **Pasting small votes for classification in large databases and on-line** (Breiman et al.; Machine Learning 1999) [[Paper]](https://link.springer.com/content/pdf/10.1023/A:1007563306331.pdf)

#### Articles

* [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)

* [What is the difference between Bagging and Boosting?](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/) **Excellent!**
  


#### Videos

* [17. Learning: Boosting](https://www.youtube.com/watch?v=UHBmv7qCey4) of MID OpenCourseWare

## Optimization

### Papers

#### 2015

* **Fortran subroutines for large-scale bound-constrained optimization** (Zhu et al.; ACM TOMS 1997) [[Paper]](http://users.iems.northwestern.edu/~nocedal/PDFfiles/lbfgsb.pdf)

#### Undated

* **Dual Coordinate Descent Methods for Logistic Regression and Maximum Entropy Models** （Yu, et al.) [[Paper]](https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf)


## Resources

* [ML Commons](https://mlcommons.org/en/)


