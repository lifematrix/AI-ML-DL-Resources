

## Papers

### 2020

* **Meta pseudo labels** (Pham et al.; 2020) [[Paper]](https://arxiv.org/pdf/2003.10580.pdf)

### 2019

* **Micro-Batch Training with Batch-Channel Normalization and Weight Standardization** (Qiao et al.) [[Paper]](https://arxiv.org/pdf/1903.10520.pdf)


### 2018

* **Exploring the limits of weakly supervised pretraining** (Mahajan, He, et al; ECCV 2018) [[Paper]](https://arxiv.org/pdf/1805.00932.pdf)

* **Mobilenetv2: Inverted residuals and linear bottlenecks** (Sandler et al.; CVPR 2018) [[Paper]](https://arxiv.org/pdf/1801.04381.pdf)

### 2018

* **Squeeze-and-Excitation Networks** ï¼ˆHu et al.; CVPR 2018) [[Paper]](https://www.robots.ox.ac.uk/~vgg/publications/2018/Hu18/hu18.pdf)

### 2016

* **Identity Mappings in Deep Residual Networks** (He et al.; ECCV 2016 camera-read) [[Paper]](https://arxiv.org/pdf/1603.05027.pdf)


### 2015

* **Deep Residual Learning for Image Recognition** (He et al. Cited by 71k) [[Paper]](https://arxiv.org/pdf/1512.03385.pdf)

* **Conditional Convolutional Neural Network for Modality-aware Face Recognition** (Xiong et al.; ICCV 2015) [[Paper]](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Xiong_Conditional_Convolutional_Neural_ICCV_2015_paper.pdf)


## Articles

* [Why Relu? Tips for using Relu. Comparison between Relu, Leaky Relu, and Relu-6](https://medium.com/@chinesh4/why-relu-tips-for-using-relu-comparison-between-relu-leaky-relu-and-relu-6-969359e48310)