

## Papers 

### 2020

* **Deep Learning Approach To Face Conditioning Using Invertible Conditional Generative Adversarial Networks (ICGAN)** (Srivastav et al; IJIRCST 2020) [[Paper]](https://www.ijircst.org/DOC/24-deep-learning-approach-to-face-conditioning-using-invertible-conditional-generative-adversarial-networks-(icgan).pdf)

* **Closed-Form Factorization of Latent Semantics in GANs** (Shen et al.; 2020)  [[Papper]](https://arxiv.org/pdf/2007.06600.pdf)
  * [project website](https://genforce.github.io/sefa/)

* **Analyzing and Improving the Image Quality of StyleGAN** (Karras et al. 2020; CVPR 2020; StyleGAN2) [[Paper]](https://arxiv.org/pdf/1912.04958.pdf)
  * [Project website](https://github.com/NVlabs/stylegan2)
  * [Pytorch implementation](https://github.com/rosinality/stylegan2-pytorch)
  * [Another implementation](https://github.com/Puzer/stylegan-encoder)
  
* **Interpreting the Latent Space of GANs for Semantic Face Editing** (Shen et al.; CVPR 2020) [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Interpreting_the_Latent_Space_of_GANs_for_Semantic_Face_Editing_CVPR_2020_paper.pdf)

* **StyleGAN2 Distillation for Feed-forward Image Manipulation** (Viazovetskyi et al.; ECCV 2020) [[Paper]](https://arxiv.org/pdf/2003.03581.pdf) [[Dataset & Code]](https://github.com/EvgenyKashin/stylegan2-distillation)

* **Image2StyleGAN++: How to Edit the Embedded Images?** (Abdal et al.; CVPR 2020) [[Papper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Abdal_Image2StyleGAN_How_to_Edit_the_Embedded_Images_CVPR_2020_paper.pdf)
  * [[Code] by pacifinapacific](https://github.com/pacifinapacific/StyleGAN_LatentEditor)
  * [[Code by Bartzi]](https://github.com/Bartzi/one-model-to-reconstruct-them-all)

* **Collaborative Learning for Faster StyleGAN Embedding** (Guan et al.; 2020) [[Paper]](https://arxiv.org/pdf/2007.01758.pdf)

* **Generative Pretraining from Pixels** (Chen et al.; OpenAI 2020) [[Paper]](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)

* **Adversarial Latent Autoencoders** (Pidhorskyi et al.; CVPR 2020) [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Pidhorskyi_Adversarial_Latent_Autoencoders_CVPR_2020_paper.pdf)

* **One Model to Reconstruct Them All: A Novel Way to Use the Stochastic Noise in StyleGAN** (Bartz et al.; 2020) [[Paper]](https://arxiv.org/pdf/2010.11113)

* **Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation** (Richardson et al.; 2020) [[Paper]](https://arxiv.org/pdf/2008.00951v1.pdf)
  * [Official code](https://github.com/eladrich/pixel2style2pixel)

* **Unified Generative Adversarial Networks for Controllable Image-to-Image Translation** (Tang et al.; 2020) [[Paper]](https://arxiv.org/pdf/1912.06112.pdf)

* **StyleFlow: Attribute-conditioned Exploration of StyleGAN-Generated Images using Conditional Continuous Normalizing Flows** (Abdal et al.;) [[Paper]](https://arxiv.org/pdf/2008.02401.pdf)

* **SEAN: Image Synthesis with Semantic Region-Adaptive Normalization** (Zhu et al.; CVPR 2020 oral) [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_SEAN_Image_Synthesis_With_Semantic_Region-Adaptive_Normalization_CVPR_2020_paper.pdf)
  * [official code](https://github.com/ZPdesu/SEAN)
  
### 2019

* **GP-GAN: Towards Realistic High-Resolution Image Blending** (Wu et al; ACMMM 2019) [[Paper]](https://arxiv.org/abs/1703.07195)

* **Tutorial: Deriving the Standard Variational Autoencoder (VAE) Loss Function** (Odaibo et al.; 2019) [[Paper]](https://arxiv.org/abs/1907.08956)

* **Large scale GAN training for high fidelity natural image synthesis**(BigGAN) (Brock et al.; ICLR 2019; Cited by 1097) [[Paper]](https://arxiv.org/pdf/1809.11096.pdf)

* **Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?** (Abdal et al.; ICCV 2019) [[Paper]](https://arxiv.org/pdf/1904.03189.pdf)
  * [Code](https://github.com/woctezuma/stylegan2-projecting-images)

* **Improved Precision and Recall Metric for Assessing Generative Models** (Kynkäänniemi et al.; NeurIPS 2019) [[Paper]](https://arxiv.org/pdf/1904.06991)

* **Do Deep Generative Models Know What They Don't Know?** (Nalisnick et al.; ICLR 2019; DeepMind) [[Paper]](https://arxiv.org/pdf/1810.09136.pdf)

* **A Style-Based Generator Architecture for Generative Adversarial Networks** (Karras et al.; CVPR 2019) [[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)
  * [Encoder for official Tensorflow Implementation](https://github.com/pbaylies/stylegan-encoder)

### 2018

* **Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks** (Zhu et al.; ICCV 2017; Cited by 6.7k) [[Paper]](https://arxiv.org/abs/1703.10593)

* **Progressive Growing of GANs for Improved Quality, Stability, and Variation(PG-GAN)** (Karras et al.; ICLR 2018) [[Paper]](https://arxiv.org/abs/1710.10196)
  * [Official Implementation of PGGAN](https://github.com/tkarras/progressive_growing_of_gans)
  * [[Code of tadax]](https://github.com/tadax/pggan)
  * [[Code for creating CelebA-HQ dataset by suvojit-0x55aa]](https://github.com/suvojit-0x55aa/celebA-HQ-dataset-download) 
  * [[Code for creating CelebA-HQ dataset by willylulu]](https://github.com/willylulu/celeba-hq-modified)

* **CartoonGAN: Generative Adversarial Networks for Photo Cartoonization** (Chen et al; CVPR 2018) [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf)

* **Pros and Cons of GAN Evaluation Measures** (Borji Ali; 2018) [[Paper]](https://arxiv.org/abs/1802.03446)

* **Conditional Wasserstein Generative Adversarial Networks** (Fabbri et al.; 2018) [[Paper]](https://cameronfabbri.github.io/papers/conditionalWGAN.pdf) [[github.io]](https://cameronfabbri.github.io/)

* **Transferring GANs: generating images from limited data** (Wang et al.; 2018) [[Paper]](https://openaccess.thecvf.com/content_ECCV_2018/papers/yaxing_wang_Transferring_GANs_generating_ECCV_2018_paper.pdf)

* **A Note on the Inception Score** (Barratt et al.; 2018; cited 228) [[Paper]](https://arxiv.org/pdf/1801.01973.pdf)

* **Spectral Normalization for Generative Adversarial Networks** (Miyato et al.; ICLR 2018; cited 1305) [[Paper]](https://arxiv.org/pdf/1802.05957.pdf)
  * An article [GAN — Spectral Normalization](https://medium.com/@jonathan_hui/gan-spectral-normalization-893b6a4e8f53) by Jonathan Hui
  
* **Large Scale GAN Training for High Fidelity Natural Image Synthesis** (Brock et al.; 2018) [[Paper]](https://arxiv.org/pdf/1809.11096.pdf)

* **Inverting The Generator Of A Generative Adversarial Network (II)** (Creswell et al.; 2018) [[Paper]](https://arxiv.org/pdf/1802.05701.pdf)

* **Glow: Generative Flow with Invertible 1x1 Convolutions** (Kingma et al.; 2018) [[Paper]](https://arxiv.org/abs/1807.03039)

* **High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs** (Wang et al. 2018) [[Paper]](https://arxiv.org/pdf/1711.11585.pdf) [[Code]](https://github.com/NVIDIA/pix2pixHD)

* **StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation** (Choi et al.; CVPR 2018) [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.pdf)

* **Pose Guided Person Image Generation** (Ma et al.; NIPS 2017) [[Paper]](https://arxiv.org/pdf/1705.09368.pdf)

### 2017
    
* **Image-to-Image Translation with Conditional Adversarial Networks** (Isola et al; CVPR 2017; Cited by 7k) [[Paper]](https://arxiv.org/abs/1611.07004)
  * [[Code]](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
  * [[Tensorflow Official Tutorial]](https://www.tensorflow.org/tutorials/generative/pix2pix)

* **A Two Stage GAN for High Resolution Retinal Image Generation and Segmentation** (Andreini et al.) [[Paper]](https://arxiv.org/abs/1907.12296)

* **Stabilizing Training of Generative Adversarial Networks through Regularization** (Roth et al; NIPS 2017) [[Paper]](https://arxiv.org/abs/1705.09367) [[Code]](https://github.com/rothk/Stabilizing_GANs)

* **Learning from simulated and unsupervised images through adversarial training** (Shrivastava et al.; CVPR 2017) [[Paper]](https://openaccess.thecvf.com/content_cvpr_2017/papers/Shrivastava_Learning_From_Simulated_CVPR_2017_paper.pdf)

* **Towards Principled Methods for Training Generative Adversarial Networks** (Arjovsky el al.; 2017) [[Paper]](https://arxiv.org/abs/1701.04862)

* **Wasserstein GAN** (Arjovsky el al.; 2017) [[Paper]](https://arxiv.org/abs/1701.078750)

* **Improved Training of Wasserstein GANs** (Gulrajani et al.; 2017) [[Paper]](https://arxiv.org/abs/1704.00028)

* **Energy-based Generative Adversarial Network** (Zhao el al.; 2017) [[Paper]](https://arxiv.org/abs/1609.03126)

* **Unpaired image-to-image translation using cycle-consistent adversarial networks** (Zhu et al.; ICCV 2017; cited by 5804)[[Paper]](https://arxiv.org/abs/1703.10593)

* **GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium** (Heusel et al. NIPS 2017) [[Paper]](http://papers.nips.cc/paper/7240-gans-trained-by-a-two-time-scale-update-rule-converge-to-a-local-nash-equilibrium.pdf)

* **Megapixel size image creation using generative adversarial networks** (Marchesi; 2017) [[Paper]](https://arxiv.org/pdf/1706.00082.pdf)

* **Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization** (Huang et al.; ICCV 2017; Cited by 929) [[Paper]](https://arxiv.org/pdf/1703.06868.pdf)

* **A Learned Representation For Artistic Style** (Dumoulin et al.; ICLR 2017) [[Paper]](https://arxiv.org/pdf/1610.07629.pdf)
  * [[Official Code]](https: //github.com/xunhuang1995/AdaIN-style)

* **Improvedtexture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis.** (Ulyanov et al.; CVPR 2017) [[Paper]](https://openaccess.thecvf.com/content_cvpr_2017/papers/Ulyanov_Improved_Texture_Networks_CVPR_2017_paper.pdf)


### 2016

* **Improved Techniques for Training GANs** (Salimans et al; NIPS 2016) [[Paper]](https://arxiv.org/abs/1606.03498)

* **Invertible Conditional GANs for image editing** (Perarnau et al; NIPS 2016) [[Paper]](https://arxiv.org/abs/1611.06355)

* **Conditional Image Synthesis With Auxiliary Classifier GANs** (Odena et al.; 2016) [[Paper]](https://arxiv.org/abs/1610.09585)
  * [Code by Lukedeo](https://github.com/lukedeo/keras-acgan)

* **Perceptual losses for real-time style transfer and super-resolution** (Johnson et al.; ECCV 2016; Cited by 4k) [[Paper]](https://arxiv.org/pdf/1603.08155.pdf)
  * [[Pytorch implementation by dxyang]](https://github.com/dxyang/StyleTransfer)

* **Inverting The Generator Of A Generative Adversarial Network** (Cresweell et al.; NIPS 2016) [[Paper]](https://arxiv.org/pdf/1611.05644.pdf)

* **Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks** (Radford et al.; ICLR 2016; Cited by 7605) [[Paper]](https://arxiv.org/pdf/1511.06434.pdf)

* **Generative Visual Manipulation on the Natural Image Manifold** (Zhu et al.; ECCV 2016) [[Paper]](https://arxiv.org/pdf/1609.03552.pdf)

* **Image Style Transfer Using Convolutional Neural Networks** (Gatys et al.; CVPR 2016) [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)

* **Instance normalization: The missing ingredient for fast stylization** (Ulyanov et al.; 2016) [[Paper]](https://arxiv.org/pdf/1607.08022)


### 2015

* **Adversarial autoencoders** (Makhzani et al.; 2015) [[Paper]](https://arxiv.org/abs/1511.05644)

* **Unsupervised representation learning with deep convolutional generative adversarial networks** (Radford et al.;ICLR 2016; Cited by 7396) [[Paper]](https://arxiv.org/pdf/1511.06434.pdf)

* **A Neural Algorithm of Artistic Style** (Gatys et al.; 2015) [[Paper]](https://arxiv.org/pdf/1508.06576.pdf)

* **NICE: Non-linear Independent Components Estimation** (Dinh et al. ICLR 2015) [[Paper]](https://arxiv.org/pdf/1410.8516.pdf)

### 2014

* **Conditional Generative Adversarial Nets** (Mirza et al) [[Paper]](https://arxiv.org/abs/1411.1784)
  * [code by zhangqianhui](https://github.com/zhangqianhui/Conditional-GAN)
  * [Code by eriklindernoren, a very comprehensive repo](https://github.com/eriklindernoren/Keras-GAN)

* **Auto-Encoding Variational Bayes** (Kingma et al; 2014; Cited by 9877) [[Paper]](https://arxiv.org/abs/1312.6114)
  * Agustinus Kristiadi's [article](https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/) provided very intuitive and clean explanation.





## Articles

### Metrics of GAN

* [GAN — How to measure GAN performance?](https://medium.com/@jonathan_hui/gan-how-to-measure-gan-performance-64b988c47732) by Jonathan Hui


### Misc
* [**Real worlds GANs | Common Probblems**](https://developers.google.com/machine-learning/gan/problems)
* [**Conditional — DCGAN in TensorFlow**](https://medium.com/@sam.maddrellmander/conditional-dcgan-in-tensorflow-336f8b03b7b6) [[code]](https://gitlab.cern.ch/smaddrel/conditional-DCGAN)
  * This article and code is based on the [[repo]](https://github.com/Eyyub/tensorflow-cdcgan)
* [Image Inpainting with Deep Learning](https://medium.com/jamieai/image-inpainting-with-deep-learning-dd8555e56a32) by Tarun Bonu

### Autoregressive

* [Autoregressive Models](http://cs236.stanford.edu/assets/slides/cs236_lecture3.pdf) bny Stefano Ermon and Aditya Grover in Stanford University


## Code 

* [Keras GAN by Erik Linder-Norén](https://github.com/eriklindernoren/Keras-GAN)
* https://github.com/A2Zadeh/Variational-Autodecoder

