
## Papers

### 2020

* **Secure, privacy-preserving and federated machine learning in medical imaging** (Kaissis et al.; Nature Machine Learning 2020) [[Paper]](https://www.nature.com/articles/s42256-020-0186-1.pdf)

* **Weight Poisoning Attacks on Pre-trained Mode** (Kurita et al.; ACL 2020) [[Paper]](https://arxiv.org/pdf/2004.06660.pdf)

### 2018

* **Secure Computation for Machine Learning With SPDZ** (Chen et al.; NIPS 2018) [[Paper]](https://arxiv.org/pdf/1901.00329.pdf)

## Model Encryption

## Codes

* [TFSecured](https://github.com/dneprDroid/TFSecured)

## Articles

* [How to hide or encrypt my own keras model file(like h5) when deploying?](https://stackoverflow.com/questions/61245326/how-to-hide-or-encrypt-my-own-keras-model-filelike-h5-when-deploying)
  
* [[TensorFlow] Encrypting/decrypting a pre-trained model in mobile applications](https://medium.com/@ovechko.056/tensorflow-pretrained-model-encryption-decryption-in-mobile-apps-e3e95209716a)

* [Linkage Attack](https://www.privitar.com/glossary/linkage-attack/)


### Enclave

* [Secure enclave overview. Apple Platform Security](https://support.apple.com/guide/security/secure-enclave-sec59b0b31ff/web)

### Homomorphic Encryption

* [Homomorphic Encryption intro: Part 1: Overview and use cases](https://towardsdatascience.com/homomorphic-encryption-intro-part-1-overview-and-use-cases-a601adcff06c)