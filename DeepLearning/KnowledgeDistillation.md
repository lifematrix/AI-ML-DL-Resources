
## Papers

### 2019

* **Towards Understanding Knowledge Distillation** (Phuong et al.; PMLR 97, 2019) [[Paper]](http://proceedings.mlr.press/v97/phuong19a/phuong19a.pdf)
### 2015

* **Distilling the Knowledge in a Neural Network** (Hinton et al.; NIPS 2014) [[Paper]](https://arxiv.org/pdf/1503.02531.pdf)
  * Articles
    * [Distilling Knowledge in Neural Networks](https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Neural-Networks--VmlldzoyMjkxODk)